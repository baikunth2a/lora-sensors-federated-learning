{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "68447cd0",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import time\n",
    "import socket\n",
    "import threading\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from keras.models import Sequential\n",
    "from tensorflow import keras as K\n",
    "from keras.layers import Dense\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from sklearn.metrics import mean_squared_error"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5553e167",
   "metadata": {},
   "outputs": [],
   "source": [
    "server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "server.bind(('localhost', 12345))\n",
    "server.listen(5)\n",
    "num_of_clients = 3\n",
    "models = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "325afd16",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = pd.read_csv('dataset.csv', index_col='district_name')\n",
    "X, y = data.iloc[:,:-5].to_numpy(), data.iloc[:,-5:].to_numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "b6a0ab19",
   "metadata": {},
   "outputs": [],
   "source": [
    "model = Sequential()\n",
    "model.add(Dense(2, input_dim=X.shape[1], activation='relu'))\n",
    "model.add(Dense(40, activation='relu'))\n",
    "model.add(Dense(20, activation='relu'))\n",
    "model.add(Dense(y.shape[1], activation='linear'))\n",
    "model.compile(loss='mean_squared_error', optimizer=Adam(learning_rate=0.01))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ed8aaadb",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Randomly populate the initial model\n",
    "weights = model.get_weights()\n",
    "for i in range(len(weights)):\n",
    "    weights[i] = np.random.random(weights[i].shape)\n",
    "model.set_weights(weights)\n",
    "\n",
    "# Save the initial model to a file\n",
    "model.save('models/model.h5', save_format='h5')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "24497a16",
   "metadata": {},
   "outputs": [],
   "source": [
    "def averaging_thread():\n",
    "    while True:\n",
    "        if len(models) == num_of_clients:\n",
    "            global_weights = model.get_weights()\n",
    "            new_weights = []\n",
    "            for i in range(len(global_weights)):\n",
    "                weight_sum = np.zeros(global_weights[i].shape)\n",
    "                for j in range(len(models)):\n",
    "                    weight_sum += models[j].get_weights()[i]\n",
    "                new_weights.append(weight_sum / len(models))\n",
    "            model.set_weights(new_weights)\n",
    "            model.save('models/model.h5', save_format='h5')\n",
    "            print(\"global model updated!\")\n",
    "            models.clear()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "3d4ce383",
   "metadata": {},
   "outputs": [],
   "source": [
    "def send_model(client):\n",
    "    with open('models/model.h5', 'rb') as f:\n",
    "        data = f.read()\n",
    "    client.sendall(data)\n",
    "    client.sendall(b'END')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "e29a6cc4",
   "metadata": {},
   "outputs": [],
   "source": [
    "def check_client_start(client):\n",
    "    message = client.recv(4096).decode()\n",
    "    return True if message == \"model_initialized\" else False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "1eaa6954",
   "metadata": {},
   "outputs": [],
   "source": [
    "def receive_and_save(client, addr):\n",
    "    data = b''\n",
    "    while True:\n",
    "        packet = client.recv(4096)\n",
    "        data += packet\n",
    "        if b'END' in data:\n",
    "                with open(f'models/client_model_{addr}.h5', 'wb') as f:\n",
    "                    f.write(data[:data.index(b'END')])\n",
    "                client_model = K.models.load_model(f'models/client_model_{addr}.h5')\n",
    "                models.append(client_model)\n",
    "                break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "6553e03f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Create a new thread for each client\n",
    "def client_thread(client, addr):\n",
    "    print(\"Client connected from: \",addr)\n",
    "    send_model(client)\n",
    "    start = check_client_start(client)\n",
    "    while start:\n",
    "        message = client.recv(4096).decode()\n",
    "        if message == \"request_global_model\":\n",
    "            send_model(client)\n",
    "        time.sleep(1)\n",
    "        client.sendall(\"send_updated_model\".encode())\n",
    "        receive_and_save(client, addr)\n",
    "        time.sleep(5)\n",
    "    client.shutdown(socket.SHUT_WR)\n",
    "    client.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "2a7d01ba",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Server listening...\n",
      "Client connected from:  ('127.0.0.1', 60936)\n",
      "Client connected from:  ('127.0.0.1', 60957)\n",
      "Client connected from:  ('127.0.0.1', 60959)\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n",
      "global model updated!\n"
     ]
    }
   ],
   "source": [
    "# Start the server\n",
    "server = socket.socket(socket.AF_INET, socket.SOCK_STREAM)\n",
    "server.bind(('localhost', 12345))\n",
    "server.listen(5)\n",
    "print(\"Server listening...\")\n",
    "\n",
    "averaging_thread = threading.Thread(target=averaging_thread)\n",
    "averaging_thread.start()\n",
    "\n",
    "thread = []\n",
    "for i in range(num_of_clients):\n",
    "    client, addr = server.accept()\n",
    "    thread.append(threading.Thread(target=client_thread, args=(client, addr)))\n",
    "    thread[i].start()\n",
    "\n",
    "#Close the server socket\n",
    "server.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9d5d2fe2",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.12"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
